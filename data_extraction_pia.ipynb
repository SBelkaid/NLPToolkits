{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import json\n",
    "import codecs\n",
    "    \n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "{'Arg1': {'CharacterSpanList': [[2493, 2517]],\n",
      "          'RawText': 'and told them to cool it',\n",
      "          'TokenList': [[2493, 2496, 465, 15, 8],\n",
      "                        [2497, 2501, 466, 15, 9],\n",
      "                        [2502, 2506, 467, 15, 10],\n",
      "                        [2507, 2509, 468, 15, 11],\n",
      "                        [2510, 2514, 469, 15, 12],\n",
      "                        [2515, 2517, 470, 15, 13]]},\n",
      " 'Arg2': {'CharacterSpanList': [[2526, 2552]],\n",
      "          'RawText': \"they're ruining the market\",\n",
      "          'TokenList': [[2526, 2530, 472, 15, 15],\n",
      "                        [2530, 2533, 473, 15, 16],\n",
      "                        [2534, 2541, 474, 15, 17],\n",
      "                        [2542, 2545, 475, 15, 18],\n",
      "                        [2546, 2552, 476, 15, 19]]},\n",
      " 'Connective': {'CharacterSpanList': [[2518, 2525]],\n",
      "                'RawText': 'because',\n",
      "                'TokenList': [[2518, 2525, 471, 15, 14]]},\n",
      " 'DocID': 'wsj_1000',\n",
      " 'ID': 14887,\n",
      " 'Sense': ['Contingency.Cause.Reason'],\n",
      " 'Type': 'Explicit'}\n",
      "<class 'dict'>\n",
      "{'CharacterSpanList': [[2493, 2517]],\n",
      " 'RawText': 'and told them to cool it',\n",
      " 'TokenList': [[2493, 2496, 465, 15, 8],\n",
      "               [2497, 2501, 466, 15, 9],\n",
      "               [2502, 2506, 467, 15, 10],\n",
      "               [2507, 2509, 468, 15, 11],\n",
      "               [2510, 2514, 469, 15, 12],\n",
      "               [2515, 2517, 470, 15, 13]]}\n"
     ]
    }
   ],
   "source": [
    "# View data structure: json\n",
    "# List of dicts that can have dicts or lists as values\n",
    "# \n",
    "\n",
    "with codecs.open ('tutorial/conll16st-en-01-12-16-trial/relations.json', 'r', encoding = 'utf-8') as pdtb_file:\n",
    "    \n",
    "\n",
    "    # Assign all relations (a list) to a variable\n",
    "    relations = [json.loads(x) for x in pdtb_file];\n",
    "    \n",
    "# Assign one relation to a variable\n",
    "example_relation = relations[10]\n",
    "\n",
    "# Assign part of the list to a variable\n",
    "example_relations = relations[:4]\n",
    "\n",
    "# Explore the data structure:\n",
    "# List\n",
    "print(type(example_relations))\n",
    "\n",
    "# Dict\n",
    "print(type(example_relation))\n",
    "pprint.pprint(example_relation)\n",
    "\n",
    "# Assign part of a list element to a variable:\n",
    "arg1 = example_relation['Arg1']\n",
    "# Dict\n",
    "print(type(arg1))\n",
    "pprint.pprint(arg1)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "2\n",
      "1\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Open json file containing the parses and assign them to a variable:\n",
    "with codecs.open('tutorial/conll16st-en-01-12-16-trial/parses.json', 'r', encoding = 'utf8') as parse_file:\n",
    "    parses = json.load(parse_file)\n",
    "    \n",
    "# Explore data structure\n",
    "print(type(parses))\n",
    "\n",
    "example_parse = list(parses.items())[0]\n",
    "print(len(example_parse))\n",
    "\n",
    "example_parse_value = list(parses.values())\n",
    "print(len(example_parse_value))\n",
    "print(type(example_parse_value[0]))\n",
    "#pprint.pprint(example_parse_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wsj_1000\n",
      "15\n",
      "15\n",
      "15\n",
      "( (S (NP (PRP We)) (VP (VBP 've) (VP (VP (VBN talked) (PP (TO to) (NP (NP (NNS proponents)) (PP (IN of) (NP (NN index) (NN arbitrage)))))) (CC and) (VP (VBD told) (NP (PRP them)) (S (VP (TO to) (VP (VB cool) (NP (PRP it)) (SBAR (IN because) (S (NP (PRP they)) (VP (VBP 're) (VP (VBG ruining) (NP (DT the) (NN market)))))))))))) (. .)) )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Work with example relation (defined above)\n",
    "\n",
    "# Get doc_id of the example\n",
    "example_doc_id = example_relation['DocID']\n",
    "print(example_doc_id)\n",
    "# Get sentence id of arg1, arg2 and the connective (which is given in the tutorial as 15, but we \n",
    "# know it is list index 3 \n",
    "# in the token list)\n",
    "\n",
    "example_sentence_id_arg1 = example_relation['Arg1']['TokenList'][0][3]\n",
    "example_sentence_id_c = example_relation['Connective']['TokenList'][0][3]\n",
    "example_sentence_id_arg2 = example_relation['Arg2']['TokenList'][0][3]\n",
    "\n",
    "# The sentence ids could be different (in the case of arg1 in the previous sentence), but here they are the same:\n",
    "print(example_sentence_id_arg1)\n",
    "print(example_sentence_id_c)\n",
    "print(example_sentence_id_arg2)\n",
    "\n",
    "# Print parse tree of example relations (which happens to be in one sentence):\n",
    "print(parses[example_doc_id]['sentences'][example_sentence_id_arg1]['parsetree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "We PRP\n",
      "'ve VBP\n",
      "talked VBN\n",
      "to TO\n",
      "proponents NNS\n",
      "of IN\n",
      "index NN\n",
      "arbitrage NN\n",
      "and CC\n",
      "told VBD\n",
      "them PRP\n",
      "to TO\n",
      "cool VB\n",
      "it PRP\n",
      "because IN\n",
      "they PRP\n",
      "'re VBP\n",
      "ruining VBG\n",
      "the DT\n",
      "market NN\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "# Get words and POS \n",
    "\n",
    "example_sentence = (parses[example_doc_id]['sentences'][example_sentence_id_arg1])\n",
    "#pprint.pprint(example_sentence['words'])\n",
    "\n",
    "# Explore data structure\n",
    "print(type(example_sentence['words']))\n",
    "print(type(example_sentence['words'][0][1]))\n",
    "#pprint.pprint(exampe_sentence['words'])\n",
    "\n",
    "\n",
    "# Print words and their POS:\n",
    "for word in example_sentence['words']:\n",
    "    print(word[0], word[1]['PartOfSpeech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( (S (NP (PRP We)) (VP (VBP 've) (VP (VP (VBN talked) (PP (TO to) (NP (NP (NNS proponents)) (PP (IN of) (NP (NN index) (NN arbitrage)))))) (CC and) (VP (VBD told) (NP (PRP them)) (S (VP (TO to) (VP (VB cool) (NP (PRP it)) (SBAR (IN because) (S (NP (PRP they)) (VP (VBP 're) (VP (VBG ruining) (NP (DT the) (NN market)))))))))))) (. .)) )\n",
      "\n",
      "<class 'str'>\n",
      "<class 'nltk.tree.Tree'>\n",
      "\n",
      "\n",
      "height of the tree\n",
      "\n",
      "15\n",
      "\n",
      "\n",
      "Get the constituents\n",
      "\n",
      "43\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "# Explore parse tree\n",
    "\n",
    "from nltk.tree import Tree\n",
    "\n",
    "example_tree = parses[example_doc_id]['sentences'][example_sentence_id_arg1]['parsetree']\n",
    "\n",
    "print(example_tree)\n",
    "print(type(example_tree))\n",
    "\n",
    "# Load string as tree:\n",
    "\n",
    "tree_nltk = Tree.fromstring(example_tree)\n",
    "print(type(tree_nltk))\n",
    "\n",
    "# Parsing the tree:\n",
    "\n",
    "#print(tree_nltk.flatten())\n",
    "\n",
    "# Draw your tree :-) \n",
    "#tree_nltk.draw() \n",
    "#tree_nltk.freeze()\n",
    "\n",
    "# Height of the tree\n",
    "\n",
    "print('\\n\\nheight of the tree\\n')\n",
    "tree_height = tree_nltk.height()\n",
    "print(tree_height)\n",
    "\n",
    "# Get all constituents of a sentence:\n",
    "\n",
    "print('\\n\\nGet the constituents\\n')\n",
    "\n",
    "# Make a list to collect the constituents\n",
    "subtree_list = []\n",
    "\n",
    "# As far as I understand, the filter function in the subtrees function shows only subtrees (i.e. consituents)\n",
    "# of the selected depth. We want all possible constituents (maybe not the smallest ones consisting of only one\n",
    "# word, but here I haven't excluded them), so I loop through all possible depths (the deepest one is the absolute \n",
    "# height of the tree).\n",
    "\n",
    "for n in range(tree_height):\n",
    "    for s in tree_nltk.subtrees(lambda t: t.height() == n):\n",
    "\n",
    "        subtree_list.append(s)\n",
    "        \n",
    "print(len(subtree_list))\n",
    "\n",
    "#print(type((subtree_list[42])))\n",
    "#pprint.pprint(subtree_list[31])\n",
    "\n",
    "constituent_set = set()\n",
    "\n",
    "for subtree in subtree_list:\n",
    "    subtree = str(subtree)\n",
    "    #print(subtree)\n",
    "    subtree_set.add(subtree)\n",
    "\n",
    "print(len(subtree_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
