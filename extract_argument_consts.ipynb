{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import json\n",
    "import codecs\n",
    "from nltk.tree import Tree\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify path to data to be analyzed (I entered the path to the tutorial data for now, so that the code runs)\n",
    "\n",
    "with codecs.open ('relations.json', 'r', encoding = 'utf-8') as pdtb_file:\n",
    "    \n",
    "\n",
    "    # Assign all relations (a list) to a variable\n",
    "    relations = [json.loads(x) for x in pdtb_file];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loop through relations and select only explicit relations:\n",
    "\n",
    "\n",
    "def explicit_relations(relations):\n",
    "    '''Extract all explicit relations from the relations file'''\n",
    "    relations_explicit = []\n",
    "\n",
    "    for relation in relations:\n",
    "        if relation['Type'] == 'Explicit':\n",
    "            relations_explicit.append(relation)\n",
    "    return (relations_explicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex_relations = explicit_relations(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ss_ps_relations(explicit_relations):\n",
    "    \n",
    "    '''Sort relations into same sentence and previous sentence relations'''\n",
    "\n",
    "    relations_ss = []\n",
    "    relations_ps = []\n",
    "    #relations_other = []\n",
    "\n",
    "    for relation in explicit_relations:\n",
    "        sentence_id_arg1 = relation['Arg1']['TokenList'][0][3]\n",
    "        sentence_id_connective = relation['Connective']['TokenList'][0][3]\n",
    "        sentence_id_arg2 = relation['Arg2']['TokenList'][0][3]\n",
    "    \n",
    "        if sentence_id_arg1 == sentence_id_connective == sentence_id_arg2:\n",
    "            relations_ss.append(relation)\n",
    "        elif int(sentence_id_arg1) == int(sentence_id_connective) - 1 == int(sentence_id_arg2) -1:\n",
    "            relations_ps.append(relation)\n",
    "        #else: \n",
    "            #relations_other.append(relation)\n",
    "            \n",
    "    return relations_ss, relations_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss_rel, ps_rel = ss_ps_relations(ex_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arg1': {'CharacterSpanList': [[1611, 1613], [1645, 1672]],\n",
      "          'RawText': 'or receive cash from the funds',\n",
      "          'TokenList': [[1611, 1613, 284, 11, 20],\n",
      "                        [1645, 1652, 292, 11, 28],\n",
      "                        [1653, 1657, 293, 11, 29],\n",
      "                        [1658, 1662, 294, 11, 30],\n",
      "                        [1663, 1666, 295, 11, 31],\n",
      "                        [1667, 1672, 296, 11, 32]]},\n",
      " 'Arg2': {'CharacterSpanList': [[1618, 1643]],\n",
      "          'RawText': 'their jobs are terminated',\n",
      "          'TokenList': [[1618, 1623, 287, 11, 23],\n",
      "                        [1624, 1628, 288, 11, 24],\n",
      "                        [1629, 1632, 289, 11, 25],\n",
      "                        [1633, 1643, 290, 11, 26]]},\n",
      " 'Connective': {'CharacterSpanList': [[1615, 1617]],\n",
      "                'RawText': 'if',\n",
      "                'TokenList': [[1615, 1617, 286, 11, 22]]},\n",
      " 'DocID': 'wsj_0204',\n",
      " 'ID': 3182,\n",
      " 'Sense': ['Contingency.Condition'],\n",
      " 'Type': 'Explicit'}\n"
     ]
    }
   ],
   "source": [
    "my_relation = ss_rel[0]\n",
    "pprint.pprint(my_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(relation, arg):\n",
    "    \n",
    "    \"\"\"returns DocID, sentenceID, Argument raw text and sentence_token_id in relations.json\"\"\"\n",
    "    \n",
    "    relation_id = relation['ID']\n",
    "    doc_id = relation['DocID']\n",
    "    sentence_id_arg = relation[arg]['TokenList'][0][3]\n",
    "    #arg_str = relation[arg]['RawText']   \n",
    "    \n",
    "    sentence_token_id_relations = []\n",
    "    \n",
    "    relations_token_list = relation[arg]['TokenList']\n",
    "    \n",
    "    for line in relations_token_list:\n",
    "        sentence_token_id = line[4]\n",
    "        sentence_token_id_relations.append(sentence_token_id)\n",
    "    \n",
    "    return relation_id, doc_id, sentence_id_arg,  sentence_token_id_relations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3182, 'wsj_0204', 11, [20, 28, 29, 30, 31, 32])\n"
     ]
    }
   ],
   "source": [
    "relid, docid, sid, stid = get_data(my_relation, 'Arg1')\n",
    "print(get_data(my_relation, 'Arg1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open('parses.json', 'r', encoding = 'utf8') as parse_file:\n",
    "        parses = json.load(parse_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data structure:\n",
    "\n",
    "1 dict for each argument\n",
    "\n",
    "keys: sentence-token-ids of the entire sentence containing the argument (this is not ideal, we always want to look at the sentence of the connective and the previous sentence)\n",
    "\n",
    "values: dics:\n",
    "\n",
    "        label: IN / OUT\n",
    "        token: token\n",
    "        constituent: constituent\n",
    "        parent constituent: parent constituent\n",
    "        daughter constituent: daughter constituent\n",
    "        POS: POS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parsed_sentence_token_id(doc_id, sentence_id_arg, sentence_token_id_relations):\n",
    "    \n",
    "    \"\"\"Enumerate words of a sentence in the parse file, so that they can be matched with the \n",
    "    sentence token ids in the relations file\"\"\"\n",
    "    \n",
    "    argument_id_tuples_list = []\n",
    "    \n",
    "    parsed_words_list = parses[doc_id]['sentences'][sentence_id_arg]['words']\n",
    "    \n",
    "    word_list = []\n",
    "    \n",
    "    word_dict = dict()\n",
    "    \n",
    "    for number, word in enumerate(parsed_words_list):\n",
    "        word_dict[number] = dict()\n",
    "        word_dict[number]['token'] = word[0]\n",
    "        word_list.append(word[0])\n",
    "        \n",
    "        if number in sentence_token_id_relations:\n",
    "            word_dict[number]['label'] = 'IN'\n",
    "            \n",
    "           \n",
    "        \n",
    "            argument_id_tuples_list.append((number, word[0]))\n",
    "        else:\n",
    "        \n",
    "            word_dict[number]['label'] = 'OUT'\n",
    "        \n",
    "    return argument_id_tuples_list, word_dict, word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'label': 'OUT', 'token': 'Under'},\n",
      " 1: {'label': 'OUT', 'token': 'two'},\n",
      " 2: {'label': 'OUT', 'token': 'new'},\n",
      " 3: {'label': 'OUT', 'token': 'features'},\n",
      " 4: {'label': 'OUT', 'token': ','},\n",
      " 5: {'label': 'OUT', 'token': 'participants'},\n",
      " 6: {'label': 'OUT', 'token': 'will'},\n",
      " 7: {'label': 'OUT', 'token': 'be'},\n",
      " 8: {'label': 'OUT', 'token': 'able'},\n",
      " 9: {'label': 'OUT', 'token': 'to'},\n",
      " 10: {'label': 'OUT', 'token': 'transfer'},\n",
      " 11: {'label': 'OUT', 'token': 'money'},\n",
      " 12: {'label': 'OUT', 'token': 'from'},\n",
      " 13: {'label': 'OUT', 'token': 'the'},\n",
      " 14: {'label': 'OUT', 'token': 'new'},\n",
      " 15: {'label': 'OUT', 'token': 'funds'},\n",
      " 16: {'label': 'OUT', 'token': 'to'},\n",
      " 17: {'label': 'OUT', 'token': 'other'},\n",
      " 18: {'label': 'OUT', 'token': 'investment'},\n",
      " 19: {'label': 'OUT', 'token': 'funds'},\n",
      " 20: {'label': 'IN', 'token': 'or'},\n",
      " 21: {'label': 'OUT', 'token': ','},\n",
      " 22: {'label': 'OUT', 'token': 'if'},\n",
      " 23: {'label': 'OUT', 'token': 'their'},\n",
      " 24: {'label': 'OUT', 'token': 'jobs'},\n",
      " 25: {'label': 'OUT', 'token': 'are'},\n",
      " 26: {'label': 'OUT', 'token': 'terminated'},\n",
      " 27: {'label': 'OUT', 'token': ','},\n",
      " 28: {'label': 'IN', 'token': 'receive'},\n",
      " 29: {'label': 'IN', 'token': 'cash'},\n",
      " 30: {'label': 'IN', 'token': 'from'},\n",
      " 31: {'label': 'IN', 'token': 'the'},\n",
      " 32: {'label': 'IN', 'token': 'funds'},\n",
      " 33: {'label': 'OUT', 'token': '.'}}\n"
     ]
    }
   ],
   "source": [
    "arg_token_ids, word_dict, word_list = parsed_sentence_token_id(docid, sid, stid)\n",
    "#print(arg_token_ids)\n",
    "#print(type(arg_token_ids))\n",
    "pprint.pprint(word_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Under',\n",
      " 1: 'two',\n",
      " 2: 'new',\n",
      " 3: 'features',\n",
      " 4: ',',\n",
      " 5: 'participants',\n",
      " 6: 'will',\n",
      " 7: 'be',\n",
      " 8: 'able',\n",
      " 9: 'to',\n",
      " 10: 'transfer',\n",
      " 11: 'money',\n",
      " 12: 'from',\n",
      " 13: 'the',\n",
      " 14: 'new',\n",
      " 15: 'funds',\n",
      " 16: 'to',\n",
      " 17: 'other',\n",
      " 18: 'investment',\n",
      " 19: 'funds',\n",
      " 21: ',',\n",
      " 22: 'if',\n",
      " 23: 'their',\n",
      " 24: 'jobs',\n",
      " 25: 'are',\n",
      " 26: 'terminated',\n",
      " 27: ',',\n",
      " 33: '.'}\n"
     ]
    }
   ],
   "source": [
    "def arg_rest_dict(word_dict):\n",
    "    \n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    arg_dict = dict()\n",
    "    rest_dict = dict()\n",
    "    \n",
    "\n",
    "    for number, subdict in word_dict.items():\n",
    "        \n",
    "   \n",
    "        \n",
    "        if subdict['label'] == 'IN':\n",
    "        \n",
    "         \n",
    "            arg_dict[number] = subdict['token']\n",
    "        else:\n",
    "            rest_dict[number] = subdict['token']\n",
    "    \n",
    "    return arg_dict, rest_dict\n",
    "        \n",
    "    \n",
    "my_arg_dict, my_rest_dict = arg_rest_dict(word_dict)\n",
    "pprint.pprint(my_rest_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "20 or\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def discontinuous_chunk(arg_dict):\n",
    "    \n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    my_list = list(sorted(arg_dict.items()))\n",
    "    \n",
    "    \n",
    "    slice_index = -1\n",
    "    for number, pair in enumerate(my_list):\n",
    "\n",
    "        token_id, token = pair\n",
    "        print(token_id, token)\n",
    "        token = pair[1]\n",
    "\n",
    "\n",
    "\n",
    "        next_pair = my_list[number+1]\n",
    "        \n",
    "        next_token_id = next_pair[0]\n",
    "        \n",
    "        next_token = next_pair[1]\n",
    "        #print(next_token_id, next_token)\n",
    "\n",
    "        if (next_token_id - token_id) >=2:\n",
    "            slice_index = number\n",
    "\n",
    "            break\n",
    "      \n",
    "\n",
    "            \n",
    " \n",
    "    return slice_index, my_list\n",
    "print(len(my_rest_dict))    \n",
    "slice_index, my_list = discontinuous_chunk(my_arg_dict)\n",
    "print(slice_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(20, 'or')], [(28, 'receive'), (29, 'cash'), (30, 'from'), (31, 'the'), (32, 'funds')]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "def arg_list(slice_index, sorted_list):\n",
    "    \n",
    "    '''Return a list of arguments. In case of a discontinuous argument, the list will have two items, \n",
    "    in case of a continuous argument, it will only have one.'''\n",
    "   \n",
    "  \n",
    "        \n",
    "        \n",
    "    if slice_index != -1:\n",
    "    \n",
    "        arg1_1 = sorted_list[:slice_index + 1]\n",
    "\n",
    "        arg1_2 = sorted_list[slice_index + 1:]\n",
    "\n",
    "        arg_str_list = [arg1_1, arg1_2]\n",
    "        \n",
    "    else:\n",
    "        arg_str_list = [sorted_list]\n",
    "    \n",
    "    return arg_str_list\n",
    "\n",
    "my_chunks = arg_list(slice_index, my_list)\n",
    "print(my_chunks)\n",
    "print(len(my_chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parsed_sentence(parses, doc_id, sentence_id_arg):\n",
    "    '''Return the parsed sentence as a tree'''\n",
    "    \n",
    "    parsed_sentence = parses[doc_id]['sentences'][sentence_id_arg]['parsetree']\n",
    "    \n",
    "    tree_nltk = Tree.fromstring(parsed_sentence)\n",
    "    \n",
    "\n",
    "    \n",
    "    return tree_nltk\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(28, 'receive'), (29, 'cash'), (30, 'from'), (31, 'the'), (32, 'funds')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tree = parsed_sentence(parses, docid, sid)\n",
    "#print(my_tree)\n",
    "my_chunk = my_chunks[1]\n",
    "print(my_chunk)\n",
    "len(my_chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to get the lowest constituent containing a chunk (either the entire argument, a part of the argument or \n",
    "a part of the sentence that does not belong to the argument).\n",
    "I am trying to match the items in the constituent I find to the sentence token ids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VP ['receive', 'cash', 'from', 'the', 'funds']\n"
     ]
    }
   ],
   "source": [
    "def get_chunk_constituent(tree, chunk):\n",
    "    '''Loop through the subtrees of the tree (low to high) and return the subtree if is the argument \n",
    "    or contains the argument'''\n",
    "    \n",
    "    chunk_t_list = []\n",
    "   \n",
    "    for pair in chunk:\n",
    "        n = pair[0]\n",
    "        t = pair[1]\n",
    "        chunk_t_list.append(t)\n",
    "        \n",
    "    chunk_str = ' '.join(chunk_t_list)\n",
    "    \n",
    "        \n",
    "    \n",
    "    height = tree.height()\n",
    "    \n",
    "    status = 'not found'\n",
    "    \n",
    "    \n",
    "\n",
    "    for h in range(height):\n",
    "\n",
    "        if status == 'found':\n",
    "            break\n",
    "\n",
    "        for subtree in tree.subtrees(lambda t: t.height() == h):\n",
    "            \n",
    "\n",
    "            label = subtree.label()\n",
    "            \n",
    "            leaves = subtree.leaves()\n",
    "\n",
    "            my_leaves = ' '.join(subtree.leaves())\n",
    "          \n",
    "\n",
    "            if chunk == leaves:\n",
    "\n",
    "\n",
    "                my_sub = subtree.leaves()\n",
    "                status = 'found'\n",
    "                return my_sub, subtree.label()\n",
    "                break\n",
    "\n",
    "\n",
    "            elif chunk_str in my_leaves:\n",
    "                \n",
    "          \n",
    "\n",
    "                my_sub = subtree.leaves()\n",
    "                status = 'found'\n",
    "                return my_sub, subtree.label()\n",
    "\n",
    "                break\n",
    "  \n",
    "        \n",
    "    \n",
    "\n",
    "my_const, l = get_chunk_constituent(my_tree, my_chunk)\n",
    "print(l, my_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-48-39717d989393>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-48-39717d989393>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    return True\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "A = [1,2,3,4,5,6,7]\n",
    "B = [3,4,5]\n",
    "\n",
    "if l2 in l1:\n",
    "    print('yes')\n",
    "    \n",
    "if listA in listB: \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'height'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-10b80b6e9471>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent_const\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmy_const\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-10b80b6e9471>\u001b[0m in \u001b[0;36mparent_const\u001b[1;34m(tree, subtree)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtree_leaves\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaves\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mheight_const\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mheight_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'height'"
     ]
    }
   ],
   "source": [
    "def parent_const(tree, subtree):\n",
    "    \n",
    "    '''Returns parent constituent of the constituent that is the argument or the constituent that\n",
    "    contains the argument'''\n",
    "    \n",
    "    tree_leaves = ' '.join(tree.leaves())\n",
    "    \n",
    "    height_const = subtree.height()\n",
    "    height_total = tree.height()\n",
    "\n",
    "    const_leaves = ' '.join(subtree.leaves())\n",
    "  \n",
    "\n",
    "    status = 'not found'\n",
    "\n",
    "    for n in range(height_const, height_total):\n",
    "        if status == 'found':\n",
    "            break\n",
    "\n",
    "        for sub in tree.subtrees((lambda t: t.height() == n)):\n",
    "\n",
    "            label = subtree.label()\n",
    "\n",
    "\n",
    "            my_leaves = ' '.join(sub.leaves())\n",
    "    \n",
    "\n",
    "\n",
    "        if (const_leaves in my_leaves) and (const_leaves != my_leaves):\n",
    "\n",
    "            my_sub = sub\n",
    "            status = 'found'\n",
    "            return label, my_sub.leaves()\n",
    "            break\n",
    "        \n",
    "    parent_list = my_sub.leaves()\n",
    "    \n",
    "    \n",
    "                \n",
    "           \n",
    "print(parent_const(my_tree, my_const))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def daughters(subtree):\n",
    "    \n",
    "    label = subtree.label()\n",
    "    original_tree = str(subtree.flatten()).lstrip('('+label).rstrip(')').strip()\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    h = subtree.height()\n",
    "    \n",
    "    daughters_list = []\n",
    "    \n",
    "    rest_str = str(subtree.flatten()).lstrip('('+label).rstrip(')').strip()\n",
    "    \n",
    "    \n",
    "    \n",
    "    for sub in subtree.subtrees():\n",
    "        l = sub.label()\n",
    "\n",
    "        my_sub = str(sub.flatten()).lstrip('('+l).rstrip(')').strip()\n",
    "\n",
    "        \n",
    "        rest_list = rest_str.split()\n",
    "        \n",
    "        \n",
    "        if (my_sub in rest_str) and (my_sub != original_tree):\n",
    "        \n",
    "            \n",
    "            if len(my_sub) > 2 :\n",
    "            \n",
    "                daughters_list.append((my_sub, l))\n",
    "\n",
    "                rest_str = rest_str.replace(my_sub, '').strip()\n",
    "\n",
    "               \n",
    "                \n",
    "        elif len(my_sub) <= 2 and my_sub in rest_list:\n",
    "            \n",
    "            daughters_list.append((my_sub, l))\n",
    "            rest_str = rest_str.replace(my_sub, '').strip()\n",
    "\n",
    "            \n",
    "        \n",
    "    return(daughters_list)\n",
    "    \n",
    "daughters(subtree)\n",
    "#print(my_arg[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for relation in ss_rel[20:30]:\n",
    "    \n",
    "    relid, docid, sid, stid = get_data(relation, 'Arg1')\n",
    "    arg_token_ids = parsed_sentence_token_id(docid, sid, stid)\n",
    "    slice_index = discontinuous_arg(arg_token_ids)\n",
    "    my_args = arg_list(slice_index, arg_token_ids)\n",
    "    \n",
    "    for arg in my_args:\n",
    "        my_tree = parsed_sentence(parses, docid, sid)\n",
    "\n",
    "        subtree, height, total_height = get_argument_constituent(my_tree, arg)\n",
    "        print(str(subtree.flatten()))\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
