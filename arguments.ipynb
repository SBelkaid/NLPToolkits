{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I worked with this notbeook inside the development data folder, so if you would like to run the code, download it and put it in the right folder (or change the paths in the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import json\n",
    "import codecs\n",
    "from nltk.tree import Tree\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify path to data to be analyzed (I entered the path to the tutorial data for now, so that the code runs)\n",
    "\n",
    "with codecs.open ('tutorial/conll16st-en-01-12-16-trial/relations.json', 'r', encoding = 'utf-8') as pdtb_file:\n",
    "    \n",
    "\n",
    "    # Assign all relations (a list) to a variable\n",
    "    relations = [json.loads(x) for x in pdtb_file];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "{'Arg1': {'CharacterSpanList': [[783, 877]],\n",
      "          'RawText': 'Several big securities firms backed off from program '\n",
      "                     'trading a few months after the 1987 crash',\n",
      "          'TokenList': [[783, 790, 143, 4, 0],\n",
      "                        [791, 794, 144, 4, 1],\n",
      "                        [795, 805, 145, 4, 2],\n",
      "                        [806, 811, 146, 4, 3],\n",
      "                        [812, 818, 147, 4, 4],\n",
      "                        [819, 822, 148, 4, 5],\n",
      "                        [823, 827, 149, 4, 6],\n",
      "                        [828, 835, 150, 4, 7],\n",
      "                        [836, 843, 151, 4, 8],\n",
      "                        [844, 845, 152, 4, 9],\n",
      "                        [846, 849, 153, 4, 10],\n",
      "                        [850, 856, 154, 4, 11],\n",
      "                        [857, 862, 155, 4, 12],\n",
      "                        [863, 866, 156, 4, 13],\n",
      "                        [867, 871, 157, 4, 14],\n",
      "                        [872, 877, 158, 4, 15]]},\n",
      " 'Arg2': {'CharacterSpanList': [[883, 957]],\n",
      "          'RawText': 'most of them, led by Morgan Stanley & Co., moved back in '\n",
      "                     'earlier this year',\n",
      "          'TokenList': [[883, 887, 161, 5, 1],\n",
      "                        [888, 890, 162, 5, 2],\n",
      "                        [891, 895, 163, 5, 3],\n",
      "                        [895, 896, 164, 5, 4],\n",
      "                        [897, 900, 165, 5, 5],\n",
      "                        [901, 903, 166, 5, 6],\n",
      "                        [904, 910, 167, 5, 7],\n",
      "                        [911, 918, 168, 5, 8],\n",
      "                        [919, 920, 169, 5, 9],\n",
      "                        [921, 924, 170, 5, 10],\n",
      "                        [924, 925, 171, 5, 11],\n",
      "                        [926, 931, 172, 5, 12],\n",
      "                        [932, 936, 173, 5, 13],\n",
      "                        [937, 939, 174, 5, 14],\n",
      "                        [940, 947, 175, 5, 15],\n",
      "                        [948, 952, 176, 5, 16],\n",
      "                        [953, 957, 177, 5, 17]]},\n",
      " 'Connective': {'CharacterSpanList': [[879, 882]],\n",
      "                'RawText': 'But',\n",
      "                'TokenList': [[879, 882, 160, 5, 0]]},\n",
      " 'DocID': 'wsj_1000',\n",
      " 'ID': 14878,\n",
      " 'Sense': ['Comparison.Contrast'],\n",
      " 'Type': 'Explicit'}\n"
     ]
    }
   ],
   "source": [
    "# Loop through relations and select only explicit relations:\n",
    "\n",
    "# List for explicit relations:\n",
    "\n",
    "relations_explicit = []\n",
    "\n",
    "for relation in relations:\n",
    "    if relation['Type'] == 'Explicit':\n",
    "        relations_explicit.append(relation)\n",
    "        \n",
    "print(len(relations_explicit))\n",
    "pprint.pprint(relations_explicit[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Split in two lists according to arg1 in same sentence and arg1 in previous sentence:\n",
    "\n",
    "relations_ss = []\n",
    "relations_ps = []\n",
    "relations_other = []\n",
    "\n",
    "for relation in relations_explicit:\n",
    "    sentence_id_arg1 = relation['Arg1']['TokenList'][0][3]\n",
    "    sentence_id_connective = relation['Connective']['TokenList'][0][3]\n",
    "    sentence_id_arg2 = relation['Arg2']['TokenList'][0][3]\n",
    "    \n",
    "    if sentence_id_arg1 == sentence_id_connective == sentence_id_arg2:\n",
    "        relations_ss.append(relation)\n",
    "    elif int(sentence_id_arg1) == int(sentence_id_connective) - 1 == int(sentence_id_arg2) -1:\n",
    "        relations_ps.append(relation)\n",
    "    else: \n",
    "        relations_other.append(relation)\n",
    "print(len(relations_ps))\n",
    "print(len(relations_ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open parse file:\n",
    "\n",
    "with codecs.open('tutorial/conll16st-en-01-12-16-trial/parses.json', 'r', encoding = 'utf8') as parse_file:\n",
    "    parses = json.load(parse_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We would stop index arbitrage when the market is under stress\n",
      "We would stop index arbitrage when the market is under stress\n",
      "rtc's! Work didn t doesn t $50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def normalize_str(text):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    text = text.lstrip('(')\n",
    "    \n",
    "    text = text.rstrip(')')\n",
    "    text_list = text.split()\n",
    "    \n",
    "    clean_text_list = []\n",
    "    \n",
    "    for word in text_list:\n",
    "        word = word.strip()\n",
    "        clean_text_list.append(word)\n",
    "    \n",
    "    clean_text = ' '.join(clean_text_list)\n",
    "    \n",
    "    return(clean_text)\n",
    "\n",
    "my_rel = relations_ss[7]\n",
    "\n",
    "arg1_str = my_rel['Arg1']['RawText']\n",
    "print(arg1_str)\n",
    "print(normalize_str(arg1_str))\n",
    "print(normalize_str(\"(rtc's! Work\\n didn t doesn t $50\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_subtrees(parsed_sentence, const_type = 0):\n",
    "    \"\"\"\"\"\"\n",
    "    tree_nltk = Tree.fromstring(parsed_sentence)\n",
    "    \n",
    "    tree_height = tree_nltk.height()\n",
    "    \n",
    "        \n",
    "    const_tuple_list = []\n",
    "\n",
    "    for s in tree_nltk.subtrees():\n",
    "\n",
    "        label = s.label()\n",
    "        \n",
    "        if (label != '``') and (label != ''):\n",
    "            \n",
    "            subtree_tokens_str = str(s.flatten())\n",
    "            #print(type(subtree_tokens_str))\n",
    "            clean_subtree_str = normalize_str(subtree_tokens_str).lstrip(label).lstrip(' ')\n",
    "\n",
    "\n",
    "\n",
    "            if const_type != 0:\n",
    "                if label == const_type:\n",
    "                    const_tuple_list.append((label, clean_subtree_str))\n",
    "\n",
    "            else:\n",
    "\n",
    "                const_tuple_list.append((label, clean_subtree_str))\n",
    "\n",
    "\n",
    "\n",
    "    return const_tuple_list\n",
    "\n",
    "doc_id = my_rel['DocID']\n",
    "sentence_id_arg1 = my_rel['Arg1']['TokenList'][0][3]\n",
    "parsed_sentence = parses[doc_id]['sentences'][sentence_id_arg1]['parsetree']  \n",
    "\n",
    "consts = get_subtrees(parsed_sentence)\n",
    "\n",
    "#pprint.pprint(consts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wsj_1000 [0, 1, 2, 3, 4, 5]\n",
      "(14884, 'wsj_1000', 13, \"Index arbitrage doesn't work\", [1, 2, 3, 4, 5])\n",
      "(14885, 'wsj_1000', 14, 'he said that \"on an intraday basis, it has major effects', [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34])\n",
      "(14887, 'wsj_1000', 15, 'and told them to cool it', [8, 9, 10, 11, 12, 13])\n",
      "(14889, 'wsj_1000', 16, 'They said, `Too bad', [0, 1, 2, 3, 4, 5])\n",
      "(14895, 'wsj_1000', 22, \"they'd love to do away with it {program trading}\", [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18])\n",
      "(14897, 'wsj_1000', 24, \"the market's volatility disturbs him\", [2, 3, 4, 5, 6, 7])\n",
      "(14900, 'wsj_1000', 28, 'We would stop index arbitrage', [1, 2, 3, 4, 5])\n",
      "(14901, 'wsj_1000', 28, 'We would stop index arbitrage when the market is under stress', [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
      "(14905, 'wsj_1000', 32, 'this prompts others to consider the same thing', [2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "def get_data(relation, arg):\n",
    "    \n",
    "    \"\"\"returns DocID, sentenceID, Argument raw text and sentence_token_id in relations.json\"\"\"\n",
    "    \n",
    "    relation_id = relation['ID']\n",
    "    doc_id = relation['DocID']\n",
    "    sentence_id_arg = relation[arg]['TokenList'][0][3]\n",
    "    arg_str = relation[arg]['RawText']   \n",
    "    \n",
    "    sentence_token_id_relations = []\n",
    "    \n",
    "    relations_token_list = relation[arg]['TokenList']\n",
    "    \n",
    "    for line in relations_token_list:\n",
    "        sentence_token_id = line[4]\n",
    "        sentence_token_id_relations.append(sentence_token_id)\n",
    "    \n",
    "    return relation_id, doc_id, sentence_id_arg, arg_str, sentence_token_id_relations\n",
    "\n",
    "my_rel = relations_ss[3]\n",
    "my_relid, my_docid, my_sid, my_arg, my_st = get_data(my_rel, 'Arg1')\n",
    "print(my_id, my_st)\n",
    "\n",
    "for rel in relations_ss:\n",
    "    print(get_data(rel, 'Arg1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_sentence_token_id(doc_id, sentence_id_arg, sentence_token_id_relations):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    argument_id_tuples_list = []\n",
    "    \n",
    "    parsed_words_list = parses[doc_id]['sentences'][sentence_id_arg]['words']\n",
    "    \n",
    "    for number, word in enumerate(parsed_words_list):\n",
    "        \n",
    "        if number in sentence_token_id_relations:\n",
    "        \n",
    "            argument_id_tuples_list.append((number, word[0]))\n",
    "        \n",
    "        \n",
    "    return argument_id_tuples_list\n",
    "\n",
    "my_tuple_list = parse_sentence_token_id('wsj_1000', 22, my_st)\n",
    "\n",
    "# Looks good, if you compare these ids to the sentence_token_ids taken from relations.json. \n",
    "# Covers the span of the argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"`` The impression I 've got\"]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_arg_list(argument_tuples_list):\n",
    "    \n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "\n",
    "    # check if argument is interrupted by comparing to the sentence token ids in the relations.json file\n",
    "    \n",
    "    for index, pair in enumerate(argument_tuples_list):\n",
    "        if pair == argument_tuples_list[-1]:\n",
    "            break\n",
    "\n",
    "        next_pair = argument_tuples_list[index + 1]\n",
    "\n",
    "\n",
    "        if (next_pair[0] - pair[0]) > 1:\n",
    "            slice_index = index\n",
    "            \n",
    "            break\n",
    "        else:\n",
    "            slice_index = None\n",
    "    \n",
    "    argument_tokens_as_in_parsing = []\n",
    "    \n",
    "    for st_id, token in argument_tuples_list:\n",
    "        \n",
    "        argument_tokens_as_in_parsing.append(token)  \n",
    "    # Get the argument as either 1 string in a list (if it is not interrupted) or as 2 strings in a list\n",
    "    # if it is interrupted\n",
    "\n",
    "    if slice_index:\n",
    "        arg1_1 = ' '.join(argument_tokens_as_in_parsing[:slice_index + 1])\n",
    "\n",
    "        arg1_2 = ' '.join(argument_tokens_as_in_parsing[slice_index + 1:])\n",
    "\n",
    "        arg_str_list = [arg1_1, arg1_2]\n",
    "    else:\n",
    "\n",
    "        arg_str_list = [' '.join(argument_tokens_as_in_parsing)]\n",
    "    \n",
    "    \n",
    "    return arg_str_list\n",
    "\n",
    "get_arg_list(my_tuple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Map arguments to constituents\n",
    "\n",
    "def constituent_structure(relation, arg):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    # Dicts with argument as key and constituent as value (tuple: (label, constituent))\n",
    "    arg_is_const = defaultdict(list)\n",
    "    arg_starts_const = defaultdict(list)\n",
    "    arg_in_const = defaultdict(list)\n",
    "    const_part_arg = defaultdict(list)\n",
    "    \n",
    "    \n",
    "    \n",
    "    rel_id, doc_id, sentence_id_arg, arg_str, sentence_token_id_relations = get_data(relation, arg)\n",
    "    \n",
    "    arg_tuples_list = my_tuple_list = parse_sentence_token_id(doc_id, sentence_id_arg, sentence_token_id_relations)\n",
    "    \n",
    "    arg_list = get_arg_list(arg_tuples_list)\n",
    "\n",
    "\n",
    "    sentence = parses[doc_id]['sentences'][sentence_id_arg]['parsetree']\n",
    "\n",
    "    const_list = get_subtrees(sentence)\n",
    "\n",
    "\n",
    "    for argument in arg_list:\n",
    "\n",
    "\n",
    "\n",
    "        for constituent in const_list:\n",
    "\n",
    "            label, const = constituent\n",
    "    \n",
    "\n",
    "\n",
    "            # Constituents the argument is part of:\n",
    "\n",
    "            if const == argument:\n",
    "\n",
    "                arg_is_const[argument].append((label, const))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            elif const.startswith(argument):\n",
    "\n",
    "                arg_starts_const[argument].append((label, const))\n",
    "\n",
    "\n",
    "            elif argument in const:\n",
    "\n",
    "                arg_in_const[argument].append((label, const))\n",
    "\n",
    "\n",
    "\n",
    "            # Constituents that are part of the argument\n",
    "\n",
    "            if const in argument:\n",
    "                const_part_arg[argument].append((label, const))\n",
    "                \n",
    "    return rel_id, doc_id, arg_is_const, arg_starts_const, arg_in_const, const_part_arg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S Index arbitrage does n't work\n",
      "S They said , ` Too bad\n",
      "SBAR they 'd love to do away with it -LCB- program trading -RCB-\n",
      "S they 'd love to do away with it -LCB- program trading -RCB-\n",
      "SBAR the market 's volatility disturbs him\n",
      "S the market 's volatility disturbs him\n",
      "S We would stop index arbitrage when the market is under stress\n",
      "S this prompts others to consider the same thing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('arg_constituents.tsv', 'w', encoding = 'utf-8') as outfile:   \n",
    "    \n",
    "    for rel in relations_ss:\n",
    "\n",
    "        rel_id, doc_id, dict1, dict2, dict3, dict4 = constituent_structure(rel, 'Arg1')\n",
    "\n",
    "        if dict1:\n",
    "        \n",
    "            for arg, const in dict1.items():\n",
    "                for l, c in const:\n",
    "                    print(l, c)\n",
    "                    outfile.write('same sentence\\t'+str(rel_id)+'\\t'+str(doc_id)+'\\t'+arg+'\\t'+l+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'prompts', 'others', 'to', 'consider', 'the', 'same', 'thing']\n",
      "(8, ['this', 'prompts', 'others', 'to', 'consider', 'the', 'same', 'thing'], 'S')\n"
     ]
    }
   ],
   "source": [
    "# What to do with cases in which the argument does not match a constituent: try out\n",
    "\n",
    "\n",
    "arg = list(dict4.keys())\n",
    "\n",
    "arg = arg[0]\n",
    "arg_list = arg.split()\n",
    "const_list = list(dict4.values())\n",
    "\n",
    "const_str_list = []\n",
    "\n",
    "for const in const_list[0]:\n",
    "    label, c = const\n",
    "    c = c.split()\n",
    "    const_str_list.append((len(c), c, label))\n",
    "    \n",
    "longest_const = (max(const_str_list))  \n",
    "print(arg_list)\n",
    "print(longest_const)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
